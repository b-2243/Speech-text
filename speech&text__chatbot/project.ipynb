{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f18ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from SpeechRecognition) (4.14.1)\n",
      "Collecting standard-aifc (from SpeechRecognition)\n",
      "  Downloading standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\n",
      "Collecting audioop-lts (from SpeechRecognition)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting standard-chunk (from standard-aifc->SpeechRecognition)\n",
      "  Downloading standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\n",
      "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 8.1/32.9 MB 46.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 14.9/32.9 MB 38.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 17.6/32.9 MB 30.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 18.4/32.9 MB 23.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 19.1/32.9 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 20.2/32.9 MB 16.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 21.2/32.9 MB 15.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 22.5/32.9 MB 13.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 24.1/32.9 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 26.0/32.9 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 27.8/32.9 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.1/32.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.5/32.9 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 11.2 MB/s  0:00:02\n",
      "Downloading PyAudio-0.2.14-cp313-cp313-win_amd64.whl (173 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading standard_aifc-3.13.0-py3-none-any.whl (10 kB)\n",
      "Downloading standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: standard-chunk, pyaudio, audioop-lts, standard-aifc, SpeechRecognition\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [audioop-lts]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   -------------------------------- ------- 4/5 [SpeechRecognition]\n",
      "   ---------------------------------------- 5/5 [SpeechRecognition]\n",
      "\n",
      "Successfully installed SpeechRecognition-3.14.3 audioop-lts-0.2.2 pyaudio-0.2.14 standard-aifc-3.13.0 standard-chunk-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition pyaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97d2f7",
   "metadata": {},
   "source": [
    "## SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4481d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone Array (Realtek Audio', 'Microsoft Sound Mapper - Output', 'Speakers / Headphones (Realtek ', 'Primary Sound Capture Driver', 'Microphone Array (Realtek Audio)', 'Primary Sound Driver', 'Speakers / Headphones (Realtek Audio)', 'Speakers / Headphones (Realtek Audio)', 'Microphone Array (Realtek Audio)', 'Jack Mic (Realtek HD Audio Front Mic input)', 'Microphone Array (Realtek HD Audio Mic Array input)', 'Stereo Mix (Realtek HD Audio Stereo input)', 'Speakers (Realtek HD Audio output with SST)']\n"
     ]
    }
   ],
   "source": [
    "print(sr.Microphone.list_microphone_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak something...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sr.Microphone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpeak something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      9\u001b[39m     text = r.recognize_google(audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time > timeout:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[33m\"\u001b[39m\u001b[33mlistening timed out while waiting for phrase to start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    494\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak something...\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Could not understand audio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8bccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microphone with device_index=0: Microsoft Sound Mapper - Input\n",
      "Microphone with device_index=1: Microphone Array (Realtek Audio\n",
      "Microphone with device_index=2: Microsoft Sound Mapper - Output\n",
      "Microphone with device_index=3: Speakers / Headphones (Realtek \n",
      "Microphone with device_index=4: Primary Sound Capture Driver\n",
      "Microphone with device_index=5: Microphone Array (Realtek Audio)\n",
      "Microphone with device_index=6: Primary Sound Driver\n",
      "Microphone with device_index=7: Speakers / Headphones (Realtek Audio)\n",
      "Microphone with device_index=8: Speakers / Headphones (Realtek Audio)\n",
      "Microphone with device_index=9: Microphone Array (Realtek Audio)\n",
      "Microphone with device_index=10: Jack Mic (Realtek HD Audio Front Mic input)\n",
      "Microphone with device_index=11: Microphone Array (Realtek HD Audio Mic Array input)\n",
      "Microphone with device_index=12: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "Microphone with device_index=13: Speakers (Realtek HD Audio output with SST)\n",
      "Adjusting for ambient noise...\n",
      "Speak now...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     r.adjust_for_ambient_noise(source, duration=\u001b[32m1\u001b[39m)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpeak now...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     18\u001b[39m     text = r.recognize_google(audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time > timeout:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[33m\"\u001b[39m\u001b[33mlistening timed out while waiting for phrase to start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    494\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# List all available microphones with their indices\n",
    "for i, mic_name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(f\"Microphone with device_index={i}: {mic_name}\")\n",
    "\n",
    "# Replace this with the device index that matches your preferred microphone\n",
    "device_index = 5  # example, adjust based on your printed list\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone(device_index=device_index) as source:\n",
    "    print(\"Adjusting for ambient noise...\")\n",
    "    r.adjust_for_ambient_noise(source, duration=1)\n",
    "    print(\"Speak now...\")\n",
    "    audio = r.listen(source, phrase_time_limit=10)\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results; {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85cd0a",
   "metadata": {},
   "source": [
    "## Vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "666bd7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vosk\n",
      "  Downloading vosk-0.3.45-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyaudio in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from vosk) (1.17.1)\n",
      "Requirement already satisfied: requests in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from vosk) (2.32.4)\n",
      "Collecting srt (from vosk)\n",
      "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from vosk) (4.67.1)\n",
      "Collecting websockets (from vosk)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pycparser in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from cffi>=1.0->vosk) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests->vosk) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests->vosk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests->vosk) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests->vosk) (2025.8.3)\n",
      "Requirement already satisfied: colorama in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from tqdm->vosk) (0.4.6)\n",
      "Downloading vosk-0.3.45-py3-none-win_amd64.whl (14.0 MB)\n",
      "   ---------------------------------------- 0.0/14.0 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 8.7/14.0 MB 51.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.0 MB 40.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.0/14.0 MB 32.3 MB/s  0:00:00\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: srt\n",
      "  Building wheel for srt (pyproject.toml): started\n",
      "  Building wheel for srt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22641 sha256=8cdb7313a8bfd4482b3d32fc2127b13d86d23045fc8515103e8f524805d02436\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\ed\\9d\\54\\8e040c593adecbf10de5a6263add15cfefff5a033e33fda8c6\n",
      "Successfully built srt\n",
      "Installing collected packages: websockets, srt, vosk\n",
      "\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ------------- -------------------------- 1/3 [srt]\n",
      "   ------------- -------------------------- 1/3 [srt]\n",
      "   -------------------------- ------------- 2/3 [vosk]\n",
      "   -------------------------- ------------- 2/3 [vosk]\n",
      "   -------------------------- ------------- 2/3 [vosk]\n",
      "   -------------------------- ------------- 2/3 [vosk]\n",
      "   ---------------------------------------- 3/3 [vosk]\n",
      "\n",
      "Successfully installed srt-3.5.3 vosk-0.3.45 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vosk pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e331fe59",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to create a model",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# model = Model(r\"D:\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\")\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# model = Model(r\"D:\\vosk-model-en-us-0.22-lgraph\\vosk-model-en-us-0.22-lgraph\")\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# model = Model(r\"D:\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mvosk-model-en-us-0.42-gigaspeech\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mvosk-model-en-us-0.42-gigaspeech\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m rec = KaldiRecognizer(model, \u001b[32m16000\u001b[39m)\n\u001b[32m     11\u001b[39m p = pyaudio.PyAudio()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\bhaumik\\shy_hr_chatbot\\.venv\\Lib\\site-packages\\vosk\\__init__.py:57\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model_path, model_name, lang)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = _c.vosk_model_new(model_path.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle == _ffi.NULL:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFailed to create a model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: Failed to create a model"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "import json\n",
    "\n",
    "# model = Model(r\"D:\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\")\n",
    "# model = Model(r\"D:\\vosk-model-en-us-0.22-lgraph\\vosk-model-en-us-0.22-lgraph\")\n",
    "# model = Model(r\"D:\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\")\n",
    "model = Model(r\"D:\\vosk-model-en-us-0.42-gigaspeech\\vosk-model-en-us-0.42-gigaspeech\")\n",
    "\n",
    "rec = KaldiRecognizer(model, 16000)\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=4096)\n",
    "stream.start_stream()\n",
    "\n",
    "print(\"Speak now...\")\n",
    "while True:\n",
    "    data = stream.read(4000,exception_on_overflow=False)\n",
    "    if rec.AcceptWaveform(data):\n",
    "        print(json.loads(rec.Result())[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85892f05",
   "metadata": {},
   "source": [
    "## Whisper/openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12b274e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-5zjorpb_\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting more-itertools (from openai-whisper==20250625)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numba (from openai-whisper==20250625)\n",
      "  Downloading numba-0.61.2-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from openai-whisper==20250625) (2.3.2)\n",
      "Collecting tiktoken (from openai-whisper==20250625)\n",
      "  Using cached tiktoken-0.10.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from openai-whisper==20250625) (2.7.1)\n",
      "Requirement already satisfied: tqdm in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->openai-whisper==20250625)\n",
      "  Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numpy (from openai-whisper==20250625)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
      "Requirement already satisfied: filelock in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from torch->openai-whisper==20250625) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Requirement already satisfied: colorama in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from tqdm->openai-whisper==20250625) (0.4.6)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading numba-0.61.2-cp313-cp313-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 34.0 MB/s  0:00:00\n",
      "Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 12.3/30.3 MB 59.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.0/30.3 MB 38.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.5/30.3 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 17.3/30.3 MB 20.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 18.1/30.3 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 18.9/30.3 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 19.9/30.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.2/30.3 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 22.8/30.3 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.6/30.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.5/30.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.6/30.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 10.3 MB/s  0:00:02\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 10.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.4 MB/s  0:00:01\n",
      "Using cached tiktoken-0.10.0-cp313-cp313-win_amd64.whl (876 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=813318 sha256=2d1b9a9f8864ef0551f6c8c8464d918b8df086728ba3bd74a4c3a4bf9823208f\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4sfwp7nl\\wheels\\0e\\80\\9c\\02c93e9c61634842951034da68bec46cf781018d5b53bb239c\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: numpy, more-itertools, llvmlite, tiktoken, numba, openai-whisper\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.2\n",
      "\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "    Uninstalling numpy-2.3.2:\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ---------------------------------------- 0/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [more-itertools]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   -------------------- ------------------- 3/6 [tiktoken]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   --------------------------------- ------ 5/6 [openai-whisper]\n",
      "   --------------------------------- ------ 5/6 [openai-whisper]\n",
      "   ---------------------------------------- 6/6 [openai-whisper]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 more-itertools-10.7.0 numba-0.61.2 numpy-2.2.6 openai-whisper-20250625 tiktoken-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-req-build-5zjorpb_'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/whisper.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad4d75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.5.2-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: scipy in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from scipy) (2.2.6)\n",
      "Requirement already satisfied: pycparser in d:\\bhaumik\\shy_hr_chatbot\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Downloading sounddevice-0.5.2-py3-none-win_amd64.whl (363 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d9616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ Speak into your microphone... (Press Ctrl+C to stop)\n",
      "\n",
      "Speak now... 🎤\n",
      "📝 Text: \n",
      "\n",
      "Speak now... 🎤\n",
      "📝 Text: Give me wallet.\n",
      "\n",
      "Speak now... 🎤\n",
      "📝 Text: ok\n",
      "\n",
      "Speak now... 🎤\n",
      "\n",
      "🛑 Stopped listening.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load Whisper small model (CPU mode)\n",
    "model = whisper.load_model(\"small\", device=\"cpu\")\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 16000  # Whisper expects 16kHz\n",
    "CHUNK_DURATION = 5   # seconds per chunk\n",
    "\n",
    "print(\"🎙️ Speak into your microphone... (Press Ctrl+C to stop)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        print(\"\\nSpeak now... 🎤\")\n",
    "        # Record audio chunk\n",
    "        audio_chunk = sd.rec(\n",
    "            int(CHUNK_DURATION * SAMPLE_RATE),\n",
    "            samplerate=SAMPLE_RATE,\n",
    "            channels=1,\n",
    "            dtype='float32'\n",
    "        )\n",
    "        sd.wait()\n",
    "\n",
    "        # Convert to numpy array\n",
    "        audio_np = np.squeeze(audio_chunk)\n",
    "\n",
    "        # Transcribe directly from NumPy array\n",
    "        result = model.transcribe(audio_np, fp16=False)\n",
    "        print(\"📝 Text:\", result[\"text\"].strip())\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Stopped listening.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890b7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
